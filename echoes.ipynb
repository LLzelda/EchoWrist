{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"/Users/mingl/Desktop/info6120/group_project/TouchInput_Exploration-main/data_preparation\"))\n",
    "from plot_profiles import plot_profiles_split_channels, plot_profiles\n",
    "from load_audio import load_audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/mingl/Desktop/info6120/group_project/audios/session_01\"\n",
    "\n",
    "os.chdir(path)\n",
    "\n",
    "config_path = path + \"/config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get config file\n",
    "audio_config = json.load(open(config_path, 'rt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo_profile_paths = []\n",
    "diff_profile_paths = []\n",
    "frame_time_paths = []\n",
    "record_paths = []\n",
    "video_paths = []\n",
    "\n",
    "for audio_file, gt_file, video_file in zip(audio_config[\"audio\"][\"files\"], audio_config[\"ground_truth\"][\"files\"], audio_config[\"ground_truth\"][\"videos\"]):\n",
    "    echo_profile_paths.append(path + \"/\" + audio_file.split(\".\")[0] + \"_fmcw_16bit_profiles.npy\")\n",
    "    diff_profile_paths.append(path + \"/\" + audio_file.split(\".\")[0] + \"_fmcw_16bit_diff_profiles.npy\")\n",
    "    record_paths.append(path + \"/\" + gt_file)\n",
    "    frame_time_paths.append(path + \"/\" + gt_file.split(\"records\")[0] + \"frame_time.txt\")\n",
    "    video_paths.append(path + \"/\" + video_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mingl/Desktop/info6120/group_project/audios/session_01/audio_001_fmcw_16bit_profiles.npy\n",
      "/Users/mingl/Desktop/info6120/group_project/audios/session_01/audio_001_fmcw_16bit_diff_profiles.npy\n",
      "/Users/mingl/Desktop/info6120/group_project/audios/session_01/record_20250429_044416_327788_frame_time.txt\n",
      "/Users/mingl/Desktop/info6120/group_project/audios/session_01/record_20250429_044416_327788_records.txt\n",
      "/Users/mingl/Desktop/info6120/group_project/audios/session_01/record_20250429_044416_327788.mp4\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "echo_profile_path = echo_profile_paths[session_num]\n",
    "diff_profile_path = diff_profile_paths[session_num]\n",
    "frame_time_path = frame_time_paths[session_num]\n",
    "record_path = record_paths[session_num]\n",
    "video_path = video_paths[session_num]\n",
    "\n",
    "print(echo_profile_path)\n",
    "print(diff_profile_path)\n",
    "print(frame_time_path)\n",
    "print(record_path)\n",
    "print(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read record file\n",
    "record_start_frames = []\n",
    "record_start_poses = []\n",
    "record_end_poses = []\n",
    "record_classes = []\n",
    "\n",
    "with open(record_path, 'r') as record_file: \n",
    "    with open(frame_time_path, 'r') as frame_time_file: \n",
    "        records = record_file.readlines()\n",
    "        frame_times = frame_time_file.readlines()\n",
    "        frame_time_line_count = 0\n",
    "        for i in range(len(records)):\n",
    "            curr_record_line = records[i]\n",
    "            record_start_time = float(curr_record_line.split(\",\")[1])\n",
    "            record_end_time = float(curr_record_line.split(\",\")[2])\n",
    "            while record_start_time > float(frame_times[frame_time_line_count]):\n",
    "                frame_time_line_count += 1\n",
    "            record_start_frame = frame_time_line_count + 1\n",
    "            record_start_frames.append(record_start_frame)\n",
    "            record_start_pos = round((record_start_time - float(frame_times[audio_config['ground_truth']['syncing_poses'][session_num]])) * audio_config['audio']['config']['sampling_rate'] / audio_config['audio']['config']['frame_length'] + audio_config['audio']['syncing_poses'][session_num])\n",
    "            record_end_pos = round((record_end_time - float(frame_times[audio_config['ground_truth']['syncing_poses'][session_num]])) * audio_config['audio']['config']['sampling_rate'] / audio_config['audio']['config']['frame_length'] + audio_config['audio']['syncing_poses'][session_num])\n",
    "            record_start_poses.append(record_start_pos)\n",
    "            record_end_poses.append(record_end_pos)\n",
    "            #modified here \n",
    "            record_classes.append(curr_record_line.split(\",\")[3].split(\"-\")[-1].rstrip())\n",
    "        frame_time_file.close()\n",
    "    record_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get session start time\n",
    "session_start_time = audio_config[\"sessions\"][session_num][0][\"start\"]\n",
    "session_start_pos = round((session_start_time - float(frame_times[audio_config['ground_truth']['syncing_poses'][session_num]])) * audio_config['audio']['config']['sampling_rate'] / audio_config['audio']['config']['frame_length'] + audio_config['audio']['syncing_poses'][session_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 49275)\n",
      "(2420, 49275, 3)\n"
     ]
    }
   ],
   "source": [
    "# Get echo profiles\n",
    "echo_profiles = np.load(echo_profile_path)\n",
    "diff_profiles = np.load(diff_profile_path)\n",
    "\n",
    "echo_profile_img_bgr = plot_profiles_split_channels(echo_profiles, 4)\n",
    "\n",
    "# bgr to rgb\n",
    "echo_profile_img = echo_profile_img_bgr.copy()\n",
    "echo_profile_img[:,:,0] = echo_profile_img_bgr[:,:,2]\n",
    "echo_profile_img[:,:,2] = echo_profile_img_bgr[:,:,0]\n",
    "\n",
    "print(echo_profiles.shape)\n",
    "print(echo_profile_img.shape)\n",
    "# plt.imshow(echo_profile_img[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = echo_profiles[:, record_start_pos[0]:record_end_poses[0]]\n",
    "s2 = echo_profiles[:, record_start_pos[1]:record_end_poses[1]]\n",
    "s3 = echo_profiles[:, record_start_pos[2]:record_end_poses[2]]\n",
    "s4 = echo_profiles[:, record_start_pos[3]:record_end_poses[3]]\n",
    "s5 = echo_profiles[:, record_start_pos[4]:record_end_poses[4]]\n",
    "s6 = echo_profiles[:, record_start_pos[5]:record_end_poses[5]]\n",
    "s7 = echo_profiles[:, record_start_pos[6]:record_end_poses[6]]\n",
    "s8 = echo_profiles[:, record_start_pos[7]:record_end_poses[7]]\n",
    "s9 = echo_profiles[:, record_start_pos[8]:record_end_poses[8]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crop echo profiles and put text based on labels\n",
    "\n",
    "diff_profile_img_bgr = plot_profiles_split_channels(diff_profiles, 4, 30000000, -30000000)\n",
    "\n",
    "# duration_frame = int((record_start_frames[max_idx + 1] - record_start_frames[min_idx]) / (max_idx + 1 - min_idx))\n",
    "for i in range(len(record_start_frames)):   # range(min_idx, max_idx + 1):\n",
    "    # plt.text(i * duration_frame, 100, str(record_classes[i].split(\"_\")[1].rstrip()), fontsize=5, bbox=dict(facecolor='cyan', edgecolor='cyan', linewidth=1))\n",
    "    cv2.putText(diff_profile_img_bgr, str(record_classes[i]), (record_start_poses[i], 165), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 255), 2)\n",
    "\n",
    "# plt.imshow(diff_profile_img[0:600, record_start_frames[min_idx] : record_start_frames[max_idx + 1]])\n",
    "cv2.imwrite(\"test.png\", diff_profile_img_bgr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m diff_profiles \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/mingl/Desktop/info6120/group_project/audios/session_01/audio_001_fmcw_16bit_diff_profiles.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(record_start_poses) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(record_end_poses) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(record_classes)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# ── 3) Slice & label, dropping any empty/too-short segments ─────────────────\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "diff_profiles = np.load(\"/Users/mingl/Desktop/info6120/group_project/audios/session_01/audio_001_fmcw_16bit_diff_profiles.npy\")\n",
    "\n",
    "\n",
    "assert len(record_start_poses) == len(record_end_poses) == len(record_classes)\n",
    "\n",
    "# ── 3) Slice & label, dropping any empty/too-short segments ─────────────────\n",
    "segments = []\n",
    "labels   = []\n",
    "\n",
    "lengths = np.array([seg.shape[0] for seg in segments])\n",
    "target_len = int(np.percentile(lengths, 90))\n",
    "\n",
    "# 2. (Optional) down-sample\n",
    "downsample = 5\n",
    "segments = [seg[::downsample] for seg in segments]\n",
    "\n",
    "# 3. Pad or truncate\n",
    "padded = []\n",
    "for seg in segments:\n",
    "    T, C = seg.shape\n",
    "    if T < target_len:\n",
    "        pad_w = ((0, target_len - T), (0, 0))\n",
    "        seg2 = np.pad(seg, pad_w, \"constant\", constant_values=0)\n",
    "    else:\n",
    "        seg2 = seg[:target_len]\n",
    "    padded.append(seg2)\n",
    "\n",
    "X = np.stack(padded)           # → (N, target_len, C)\n",
    "y = np.array(labels)\n",
    "\n",
    "np.save(\"X2.npy\", X)   # X has shape (N, T, C, 1)\n",
    "np.save(\"y2.npy\", y)   # y has shape (N,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kept 72 / 72 segments\n",
      "Final shapes: (72, 640, 49274, 1) (72,)\n"
     ]
    }
   ],
   "source": [
    "# 1) Load your long differential echo‐profile array\n",
    "#    (shape = [T, C] where T = total time‐samples, C = channels)\n",
    "diff_profiles = np.load(\"/Users/mingl/Desktop/info6120/group_project/audios/session_01/audio_001_fmcw_16bit_diff_profiles.npy\")\n",
    "\n",
    "# 2) Re-create the lists your snippet already built:\n",
    "#    – record_start_poses: the sample index where each clap (start of a gesture) occurs\n",
    "#    – record_classes:      the string labels, e.g. [\"pos_0\",\"pos_0\",\"pos_1\",…]\n",
    "#    (If you populated these in your notebook, you can just import them here.)\n",
    "#\n",
    "# For demonstration let’s assume you already have:\n",
    "#    record_start_poses = [...]\n",
    "#    record_classes     = [...]\n",
    "#\n",
    "# Convert your class strings to integer IDs:\n",
    "assert len(record_start_poses) == len(record_end_poses) == len(record_classes)\n",
    "\n",
    "# ── 3) Slice & label, dropping any empty/too-short segments ─────────────────\n",
    "segments = []\n",
    "labels   = []\n",
    "\n",
    "for i, (start, end, cls_str) in enumerate(zip(record_start_poses,\n",
    "                                               record_end_poses,\n",
    "                                               record_classes)):\n",
    "    length = end - start\n",
    "    if length <= 0:\n",
    "        print(f\"Skipping segment {i}: start={start}, end={end}, length={length}, class={cls_str}\")\n",
    "        continue\n",
    "\n",
    "    seg = diff_profiles[start:end, :]   # → (length, channels)\n",
    "    segments.append(seg)\n",
    "    labels.append(int(cls_str))   # \"pos_3\" → 3\n",
    "\n",
    "# Quick sanity check\n",
    "print(f\"\\nKept {len(segments)} / {len(record_classes)} segments\")\n",
    "\n",
    "# ── 4) Pad or truncate each segment to fixed time-length ───────────────────────\n",
    "#    You can choose a target_len (e.g. max or some window)\n",
    "lengths   = [s.shape[0] for s in segments]\n",
    "target_len = max(lengths)   # or set target_len = 200, etc.\n",
    "\n",
    "padded = []\n",
    "for seg in segments:\n",
    "    T, C = seg.shape\n",
    "    if T < target_len:\n",
    "        pad_w = ((0, target_len - T), (0, 0))\n",
    "        seg2 = np.pad(seg, pad_w, mode=\"constant\", constant_values=0)\n",
    "    else:\n",
    "        seg2 = seg[:target_len, :]\n",
    "    padded.append(seg2)\n",
    "\n",
    "X = np.stack(padded, axis=0)            # → (N, target_len, channels)\n",
    "y = np.array(labels, dtype=np.int64)    # → (N,)\n",
    "\n",
    "# ── 5) (Optional) add channel-axis for a 2D-CNN ──────────────────────────────\n",
    "X = X[..., np.newaxis]                  # → (N, target_len, channels, 1)\n",
    "\n",
    "print(\"Final shapes:\", X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "np.save(\"X.npy\", X)   # X has shape (N, T, C, 1)\n",
    "np.save(\"y.npy\", y)   # y has shape (N,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final X.shape: (2, 712, 49274)\n",
      "Built X.shape=(2, 712, 49274), y.shape=(2,), labels range 1–1\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"/Users/mingl/Desktop/info6120/group_project/model\"\n",
    "profiles = np.load(os.path.join(data_folder,\n",
    "                                \"audio_001_fmcw_16bit_diff_profiles.npy\"))\n",
    "segments = []\n",
    "labels   = []\n",
    "\n",
    "ends = record_start_poses[1:] + [profiles.shape[0]]\n",
    "for cls_str, start, end in zip(record_classes, record_start_poses, ends):\n",
    "    seg = profiles[start:end, :]               # now end>start\n",
    "    segments.append(seg)\n",
    "    labels.append(int(cls_str))\n",
    "\n",
    "# 3c. stack into arrays\n",
    "#     Depending on your model you may need to add a “channel” axis:\n",
    "for i, seg in enumerate(segments):\n",
    "    print(f\"Segment {i:2d}: shape={seg.shape}\")\n",
    "X = np.stack(segments, axis=0)           # → (N, duration, channels)\n",
    "y = np.array(labels, dtype=np.int64)     # → (N,)\n",
    "\n",
    "print(f\"Built X.shape={X.shape}, y.shape={y.shape}, labels range {y.min()}–{y.max()}\")\n",
    "\n",
    "# ── 4. Save for downstream training ───────────────────────────────────────────\n",
    "np.save(os.path.join(data_folder, \"X.npy\"), X)\n",
    "np.save(os.path.join(data_folder, \"y.npy\"), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder based on classes and save\n",
    "def save_reorder_profiles(original_profiles, reordered_img_name, minval, maxval, record_classes, record_start_poses, record_end_poses):\n",
    "    reordered_profiles = np.zeros(original_profiles.shape)\n",
    "    done_classes = []\n",
    "    curr_profile_pos = 0\n",
    "    for curr_class in record_classes:\n",
    "        if curr_class not in done_classes:\n",
    "            for i in range(len(record_classes)):\n",
    "                if record_classes[i] == curr_class:\n",
    "                    buffer = (record_end_poses[curr_profile_pos] - record_start_poses[curr_profile_pos]) - (record_end_poses[i] - record_start_poses[i])\n",
    "                    reordered_profiles[:, record_start_poses[curr_profile_pos] + buffer : record_end_poses[curr_profile_pos]] = original_profiles[:, record_start_poses[i] : record_end_poses[i]]\n",
    "                    done_classes.append(curr_class)\n",
    "                    curr_profile_pos += 1\n",
    "\n",
    "    reordered_profile_img_bgr = plot_profiles_split_channels(reordered_profiles, 2, maxval, minval)\n",
    "    for i in range(len(done_classes)):   \n",
    "        cv2.putText(reordered_profile_img_bgr, str(done_classes[i]), (record_start_poses[i], 100), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 255), 2)\n",
    "    cv2.imwrite(reordered_img_name, reordered_profile_img_bgr)\n",
    "\n",
    "    return reordered_profiles\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder based on classes\n",
    "def reorder_profiles(original_profiles, record_classes, record_start_poses, record_end_poses):\n",
    "    reordered_profiles = np.zeros(original_profiles.shape)\n",
    "    reordered_classes = []\n",
    "    reordered_start_poses = []\n",
    "    reordered_end_poses = []\n",
    "    curr_profile_pos = 0\n",
    "    for curr_class in record_classes:\n",
    "        if curr_class not in reordered_classes:\n",
    "            for i in range(len(record_classes)):\n",
    "                if record_classes[i] == curr_class:\n",
    "                    buffer = (record_end_poses[curr_profile_pos] - record_start_poses[curr_profile_pos]) - (record_end_poses[i] - record_start_poses[i])\n",
    "                    reordered_profiles[:, record_start_poses[curr_profile_pos] + buffer : record_end_poses[curr_profile_pos]] = original_profiles[:, record_start_poses[i] : record_end_poses[i]]\n",
    "                    reordered_classes.append(curr_class)\n",
    "                    reordered_start_poses.append(record_start_poses[curr_profile_pos])\n",
    "                    reordered_end_poses.append(record_end_poses[curr_profile_pos])\n",
    "                    curr_profile_pos += 1\n",
    "\n",
    "    return reordered_profiles, reordered_classes, reordered_start_poses, reordered_end_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
